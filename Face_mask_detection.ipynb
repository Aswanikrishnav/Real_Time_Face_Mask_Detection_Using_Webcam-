{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjU9t4-G0zGK",
        "outputId": "8de1eaa7-ee74-45c3-c1dd-b6312c12f37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_6I0-rV5S_K"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/face_mask_dataset_backup/train'\n",
        "val_dir = '/content/drive/MyDrive/face_mask_dataset_backup/val'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqUFmUOJ5jOk",
        "outputId": "d658135a-fc45-43fd-eb65-af59786662a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train classes: ['with_mask', 'without_mask']\n",
            "Val classes: ['with_mask', 'without_mask']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"Train classes:\", os.listdir(train_dir))\n",
        "print(\"Val classes:\", os.listdir(val_dir))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COTWirHS5l3p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.class_indices)\n",
        "print(val_data.class_indices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KNTOv5no78z",
        "outputId": "3038cd29-75ec-4031-bec2-f6d1ea56d323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'with_mask': 0, 'without_mask': 1}\n",
            "{'with_mask': 0, 'without_mask': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Train folder structure:\")\n",
        "for cls in os.listdir(train_dir):\n",
        "    path = os.path.join(train_dir, cls)\n",
        "    print(cls, \":\", len(os.listdir(path)), \"images\")\n",
        "\n",
        "print(\"\\nValidation folder structure:\")\n",
        "for cls in os.listdir(val_dir):\n",
        "    path = os.path.join(val_dir, cls)\n",
        "    print(cls, \":\", len(os.listdir(path)), \"images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcLlpamGzbnm",
        "outputId": "573f0aec-f304-449b-a836-79c7cfc4b352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train folder structure:\n",
            "with_mask : 1120 images\n",
            "without_mask : 72375 images\n",
            "\n",
            "Validation folder structure:\n",
            "with_mask : 279 images\n",
            "without_mask : 18093 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmG1DfxX6Vgl",
        "outputId": "5ebc07e8-0800-4666-ad0c-974f6bc1c7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_balanced  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/dataset_balanced\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54VE-X7U6-t7",
        "outputId": "dda49c11-7ea4-4b83-8bac-86ed1b82eebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvvEAY_M7CZk",
        "outputId": "2f02a7cf-912c-4e6c-ef09-2c7dc9ac433d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1000144273.jpg\n",
            " 1456310679E-textChap-1Mod-3.pdf\n",
            " 16_10_24.gdoc\n",
            " 22_10_24.gdoc\n",
            " 2245023265AE4CF87D02C8B6BA991139\n",
            " 3f4a6d99-dd6d-4227-a234-b3a9eade54c5_1719583073%20-%2099.00%20To%20Aman%20%20Kesarwani%20on%20Google%20Pay.png\n",
            " Adaboost_Lab.ipynb\n",
            "'arijit sanam re.mp3'\n",
            " assignment4.txt.gz\n",
            "'Aswani krishna v'\n",
            "'Aswani Krishna V (1).pdf'\n",
            "'ASWANI KRISHNA V (1).pdf'\n",
            "'ASWANI KRISHNA V (3).gdoc'\n",
            "'ASWANI KRISHNA V (3).pdf'\n",
            "'ASWANI KRISHNA V (4).pdf'\n",
            "'ASWANI KRISHNA V (6).pdf'\n",
            "'Aswani krishna v .Bsc mathematics.pdf'\n",
            "'Aswani krishna V resume (1).pdf'\n",
            "'Aswani-Krishna-V-Resume (1).pdf'\n",
            "'Aswani krishna V resume.pdf'\n",
            "'Aswani Krishna V_resume.pdf'\n",
            " Aswani-Krishna-V-Resume.pdf\n",
            "'Aswani photo.jpeg'\n",
            "'Aswani_Resume (1).pdf'\n",
            "'Aswani_Resume (2).pdf'\n",
            "'Aswani_Resume (3).pdf'\n",
            " Aswani_Resume.pdf\n",
            " AswaniSample2025Visit.docx\n",
            " AswaniSample2025Visit.gdoc\n",
            " AswaniSample2025Visit.pdf\n",
            "'Aswani self declaration.gdoc'\n",
            " bandit.org.gdoc\n",
            " bandit.org.pdf\n",
            "'Binsa self declaration.gdoc'\n",
            "'certificate drug.jpg'\n",
            " Certificates.pdf\n",
            "'certificate with photo (1).jpg'\n",
            "'certificate with photo.jpg'\n",
            " Classroom\n",
            " CoinbaseWalletBackups\n",
            "'Colab Notebooks'\n",
            "'Copy of sonar data.gsheet'\n",
            "'Covering letter.gdoc'\n",
            "'Degree certificate (1).pdf'\n",
            "'Degree certificate (2).pdf'\n",
            "'Degree certificate (3).pdf'\n",
            "'Degree certificate.pdf'\n",
            " Doc2.docx\n",
            " face_mask_dataset_backup\n",
            " IMG-20241217-WA0272.jpg\n",
            " IMG-20251001-WA0005.jpg\n",
            "'Linux Tutorial - Introduction_assignment1.pdf'\n",
            " main_tex.gdoc\n",
            " main_tex.pdf\n",
            " main_tex.txt\n",
            " marklist.pdf\n",
            " Marklist.pdf\n",
            " paaaport_adress.heic\n",
            "'parallel and distributed computing .pdf'\n",
            "'pasport biodata (1).jpg'\n",
            "'pasport biodata.jpg'\n",
            "'passport adress (1).jpg'\n",
            "'passport adress.jpg'\n",
            " passport_biodata.heic\n",
            "'passport with photo (1).jpg'\n",
            "'passport with photo (2).jpg'\n",
            "'passport with photo.jpg'\n",
            "'photo (1).jpeg'\n",
            "'photo (1).jpg'\n",
            " photo.jpeg\n",
            " photo.jpg\n",
            " photo_passprt.jpg\n",
            "'photo with certificate.jpg'\n",
            "'photo with passport.jpg'\n",
            "'psc hallticket.gdoc'\n",
            "'psc hallticket.pdf'\n",
            " report.gdoc\n",
            "'S3 statistics.pdf'\n",
            "'S6 Ring Theory 1.pdf'\n",
            "'sakubai nadak.pdf'\n",
            " sayili.pdf\n",
            " Screenshot_20240628_192815_GPay.jpg\n",
            "'Screenshot_20240701_121459_GPay (1).jpg'\n",
            "'Screenshot_20240701_121459_GPay (2).jpg'\n",
            " Screenshot_20240701_121459_GPay.jpg\n",
            " Signature.jpeg\n",
            "'sreelekshmi self decla.gdoc'\n",
            "'sreelekshmi self decla.pdf'\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document (3).gdoc'\n",
            "'Untitled document (4).gdoc'\n",
            "'Untitled document (5).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " VID-20231106-WA0061_004.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/face_mask_dataset_backup\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m5fHbR88g7u",
        "outputId": "feb75daa-1114-43d2-a271-26b12f1d1a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, shutil\n",
        "\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/face_mask_dataset_backup/train'\n",
        "val_dir = '/content/drive/MyDrive/face_mask_dataset_backup/val'\n",
        "\n",
        "balanced_dir = '/content/drive/MyDrive/face_mask_dataset_balanced'\n",
        "os.makedirs(os.path.join(balanced_dir, 'train/with_mask'), exist_ok=True)\n",
        "os.makedirs(os.path.join(balanced_dir, 'train/without_mask'), exist_ok=True)\n",
        "os.makedirs(os.path.join(balanced_dir, 'val/with_mask'), exist_ok=True)\n",
        "os.makedirs(os.path.join(balanced_dir, 'val/without_mask'), exist_ok=True)\n",
        "\n",
        "# Limits for balancing\n",
        "limit_train = 1100\n",
        "limit_val = 275\n",
        "\n",
        "# Balance training set\n",
        "for cls in ['with_mask', 'without_mask']:\n",
        "    src_folder = os.path.join(train_dir, cls)\n",
        "    dst_folder = os.path.join(balanced_dir, 'train', cls)\n",
        "    imgs = os.listdir(src_folder)\n",
        "    random.shuffle(imgs)\n",
        "    for img in imgs[:limit_train]:\n",
        "        shutil.copy(os.path.join(src_folder, img), os.path.join(dst_folder, img))\n",
        "\n",
        "# Balance validation set\n",
        "for cls in ['with_mask', 'without_mask']:\n",
        "    src_folder = os.path.join(val_dir, cls)\n",
        "    dst_folder = os.path.join(balanced_dir, 'val', cls)\n",
        "    imgs = os.listdir(src_folder)\n",
        "    random.shuffle(imgs)\n",
        "    for img in imgs[:limit_val]:\n",
        "        shutil.copy(os.path.join(src_folder, img), os.path.join(dst_folder, img))\n",
        "\n",
        "print(\"✅ Balanced dataset created at:\", balanced_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U72Q4sdn-2Y-",
        "outputId": "f559090e-1e3c-4dd9-ed0e-ea59bb2a9737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Balanced dataset created at: /content/drive/MyDrive/face_mask_dataset_balanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/face_mask_dataset_balanced/train'\n",
        "val_dir = '/content/drive/MyDrive/face_mask_dataset_balanced/val'\n"
      ],
      "metadata": {
        "id": "32DnHPx3_RXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "val_dir = '/content/drive/MyDrive/face_mask_dataset_balanced/val'\n",
        "\n",
        "for cls in ['with_mask', 'without_mask']:\n",
        "    path = os.path.join(val_dir, cls)\n",
        "    print(cls, \":\", len(os.listdir(path)), \"images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nor_oqW-H_ab",
        "outputId": "11639202-cdeb-45e5-b5bb-d3d18c0a7aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with_mask : 275 images\n",
            "without_mask : 275 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDe6wfWsKOD_",
        "outputId": "90c288c1-6e90-4068-bfd7-c66fd5e59cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 550 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/face_mask_dataset_balanced/train'\n",
        "val_dir = '/content/drive/MyDrive/face_mask_dataset_balanced/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_data = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcxg09kaKZTu",
        "outputId": "3355d7e9-ac46-4f4f-d6a8-f0b40d4163b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2200 images belonging to 2 classes.\n",
            "Found 550 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - accuracy: 0.7853 - loss: 0.4514 - val_accuracy: 0.9745 - val_loss: 0.1200\n",
            "Epoch 2/10\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.9618 - loss: 0.1224 - val_accuracy: 0.9764 - val_loss: 0.0799\n",
            "Epoch 3/10\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - accuracy: 0.9734 - loss: 0.0796 - val_accuracy: 0.9782 - val_loss: 0.0684\n",
            "Epoch 4/10\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - accuracy: 0.9749 - loss: 0.0732 - val_accuracy: 0.9745 - val_loss: 0.0689\n",
            "Epoch 5/10\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - accuracy: 0.9860 - loss: 0.0524 - val_accuracy: 0.9727 - val_loss: 0.0706\n",
            "Epoch 6/10\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 2s/step - accuracy: 0.9829 - loss: 0.0520 - val_accuracy: 0.9818 - val_loss: 0.0590\n",
            "Epoch 7/10\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.9849 - loss: 0.0406 - val_accuracy: 0.9727 - val_loss: 0.0638\n",
            "Epoch 8/10\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.9842 - loss: 0.0412 - val_accuracy: 0.9836 - val_loss: 0.0600\n",
            "Epoch 9/10\n",
            "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 2s/step - accuracy: 0.9924 - loss: 0.0317 - val_accuracy: 0.9727 - val_loss: 0.0699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/face_mask_model_balanced.h5')\n",
        "print(\"✅ Model trained and saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFP4esLoLDQ6",
        "outputId": "4c0172a3-d29b-42dc-99f0-710b3d78619c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model trained and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnLlo6dqbw8r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}